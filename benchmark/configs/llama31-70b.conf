# Llama 3.1 70B Instruct Configuration

# ============================================
# Common Settings (Used by all tools)
# ============================================
MODEL_NAME="Llama-3.1-70B-Instruct"
MODEL_PATH="/home/ubuntu/models/Llama-3.1-70B-Instruct/"
MODEL_TYPE="llama"
TASK_TYPE="causal-lm"

# Compilation Settings
TORCH_DTYPE="bfloat16"
TP_DEGREE=64
PAD_TOKEN_ID=2

# Batch Size Configurations
# Format: CONTEXT_LENGTH SEQ_LENGTH
BS1_CONFIG="16384 16384"
BS2_CONFIG="8192 8704"
BS4_CONFIG="4096 4608"

# Bucketing Configuration
# BS1: Full buckets
BS1_CONTEXT_BUCKETS="256 512 1024 2048 4096 8192 10240 12288 16384"
BS1_TOKEN_BUCKETS="256 512 1024 2048 4096 8192 10240 12288 16384"

# BS2: Medium buckets
BS2_CONTEXT_BUCKETS="2048 4096 8192"
BS2_TOKEN_BUCKETS="2048 4096 8192 8704"

# BS4: Conservative buckets
BS4_CONTEXT_BUCKETS="2048 4096"
BS4_TOKEN_BUCKETS="2048 4096 4608"

# Compilation Options
COMPILE_OPTS="--on-device-sampling \
--top-k 20 \
--do-sample \
--fused-qkv \
--sequence-parallel-enabled \
--qkv-kernel-enabled \
--attn-kernel-enabled \
--mlp-kernel-enabled \
--cc-pipeline-tiling-factor 1 \
--enable-bucketing"

# Neuron Runtime Settings
NEURON_RT_VIRTUAL_CORE_SIZE=2
NEURON_RT_NUM_CORES=64
NEURON_RT_EXEC_TIMEOUT=1800
XLA_DENSE_GATHER_FACTOR=0
NEURON_RT_INSPECT_ENABLE=0

# vLLM Server Settings
VLLM_BLOCK_SIZE=16
VLLM_RPC_TIMEOUT=100000
VLLM_EXTRA_ARGS="--additional-config='{\"override_neuron_config\": {\"moe_ep_degree\": 1}}'"

# ============================================
# LLMPerf Settings (Used by run_llmperf.sh)
# ============================================

# Request Distribution (Normal Distribution)
LLMPERF_MEAN_INPUT_TOKENS=550
LLMPERF_STDDEV_INPUT_TOKENS=150
LLMPERF_MEAN_OUTPUT_TOKENS=150
LLMPERF_STDDEV_OUTPUT_TOKENS=10

# Test Configuration
LLMPERF_MAX_REQUESTS=500
LLMPERF_TIMEOUT=600
LLMPERF_NUM_CONCURRENT_REQUESTS=1

# API Settings
LLMPERF_API_TYPE="openai"  # openai, anthropic, litellm
LLMPERF_API_BASE="http://localhost:8000/v1"

# Test Levels
# Light: Quick validation (3 concurrency levels)
LLMPERF_LIGHT_CONCURRENCY=(1 2 4)

# Medium: Detailed analysis (5 concurrency levels)
LLMPERF_MEDIUM_CONCURRENCY=(1 2 4 8 16)

# Heavy: Full spectrum (8 concurrency levels)
LLMPERF_HEAVY_CONCURRENCY=(1 2 4 8 16 32 64 128)

# Input/Output Length Variations
# Format: "mean_input stddev_input mean_output stddev_output"
LLMPERF_LIGHT_VARIATIONS=(
    "256 50 64 10"      # Short
    "550 150 150 10"    # Standard
    "1024 200 256 20"   # Long
)

LLMPERF_MEDIUM_VARIATIONS=(
    "128 30 32 5"       # Very Short
    "256 50 64 10"      # Short
    "550 150 150 10"    # Standard
    "1024 200 256 20"   # Long
    "2048 300 512 30"   # Very Long
)

LLMPERF_HEAVY_VARIATIONS=(
    "128 30 32 5"       # Very Short
    "256 50 64 10"      # Short
    "512 100 128 15"    # Medium
    "550 150 150 10"    # Standard
    "1024 200 256 20"   # Long
    "2048 300 512 30"   # Very Long
    "4096 500 1024 50"  # Extra Long
)

# Additional Sampling Parameters (JSON format)
LLMPERF_SAMPLING_PARAMS='{
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 512
}'

# ============================================
# Accuracy Test Settings (Used by run_accuracy.sh)
# ============================================

# Accuracy Test Levels
# Light: Quick validation (2 datasets, limited samples)
ACCURACY_LIGHT_TESTS=(
    "mmlu:100"           # MMLU with 100 samples
    "gsm8k:50"           # GSM8K with 50 samples
)

# Medium: Standard evaluation (4 datasets, moderate samples)
ACCURACY_MEDIUM_TESTS=(
    "mmlu:500"           # MMLU with 500 samples
    "gsm8k:200"          # GSM8K with 200 samples
    "hellaswag:500"      # HellaSwag with 500 samples
    "arc_challenge:200"  # ARC Challenge with 200 samples
)

# Heavy: Full evaluation (6 datasets, full or large samples)
ACCURACY_HEAVY_TESTS=(
    "mmlu:0"             # MMLU full dataset (0 = no limit)
    "gsm8k:0"            # GSM8K full dataset
    "hellaswag:0"        # HellaSwag full dataset
    "arc_challenge:0"    # ARC Challenge full dataset
    "truthfulqa:0"       # TruthfulQA full dataset
    "winogrande:0"       # Winogrande full dataset
)

# Accuracy Test Configuration
ACCURACY_MAX_CONCURRENT_REQUESTS=1
ACCURACY_TIMEOUT=3600
ACCURACY_SERVER_PORT=8000
ACCURACY_N_VLLM_THREADS=16

# LM-Eval Client Parameters
ACCURACY_CLIENT_PARAMS_BATCH_SIZE=1
ACCURACY_CLIENT_PARAMS_NUM_FEW_SHOT=5
